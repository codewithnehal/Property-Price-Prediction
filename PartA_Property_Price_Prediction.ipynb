{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c1f368",
   "metadata": {},
   "source": [
    "# Part A: Property Price Prediction\n",
    "\n",
    "Predict the **median house value** using district-level features. This notebook covers EDA, preprocessing, **Simple Linear Regression** and **Multiple Linear Regression**, plus evaluation with **MSE**, **RMSE**, and **R²**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e8690a",
   "metadata": {},
   "source": [
    "\n",
    "# Setup\n",
    "\n",
    "This notebook installs/imports commonly used libraries.  \n",
    "If some libraries are missing in your environment, run the install cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f59a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If needed, uncomment to install dependencies in your environment\n",
    "# %pip install pandas numpy scikit-learn matplotlib seaborn joblib openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, RocCurveDisplay)\n",
    "import joblib\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2396635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data_flex(path_or_url: str):\n",
    "    \"\"\"Load CSV/Excel from a local path or URL (Google Sheets/Drive direct link supported).\n",
    "    If it's a Google Sheet viewing URL, convert it to CSV export automatically.\n",
    "    \"\"\"\n",
    "    p = str(path_or_url).strip()\n",
    "    # Try to convert Google Sheets view link to export CSV\n",
    "    if \"docs.google.com/spreadsheets\" in p and \"/edit\" in p and \"export?format=csv\" not in p:\n",
    "        # Convert to CSV export\n",
    "        key = p.split(\"/d/\")[1].split(\"/\")[0]\n",
    "        p = f\"https://docs.google.com/spreadsheets/d/{key}/export?format=csv\"\n",
    "    try:\n",
    "        if p.lower().endswith((\".xlsx\", \".xls\")):\n",
    "            df = pd.read_excel(p)\n",
    "        else:\n",
    "            df = pd.read_csv(p)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load data from '{path_or_url}'. Error: {e}\")\n",
    "    return df\n",
    "\n",
    "def quick_info(df: pd.DataFrame, name: str = \"Data\"):\n",
    "    print(f\"\\n{name} shape: {df.shape}\\n\")\n",
    "    display(df.head())\n",
    "    display(df.describe(include='all').transpose())\n",
    "    print(\"\\nMissing values per column:\\n\")\n",
    "    display(df.isna().sum().to_frame('missing'))\n",
    "    print(\"\\nDtypes:\\n\")\n",
    "    display(df.dtypes.to_frame('dtype'))\n",
    "\n",
    "def numeric_categorical_columns(df: pd.DataFrame, exclude_target: str = None):\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "    if exclude_target and exclude_target in num_cols:\n",
    "        num_cols.remove(exclude_target)\n",
    "    if exclude_target and exclude_target in cat_cols:\n",
    "        cat_cols.remove(exclude_target)\n",
    "    return num_cols, cat_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562b5bbf",
   "metadata": {},
   "source": [
    "## 1) Load Data\n",
    "\n",
    "- Provide either a local CSV/Excel path or a Google Sheet link.\n",
    "- The assignment mentions California housing data and a categorical feature like `ocean_proximity`.\n",
    "- Update `DATA_PATH_OR_URL` below to your actual file or the provided link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff3c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === User input: set your data path or Google Sheet link ===\n",
    "# Example (Google Sheet from assignment doc): paste the link below\n",
    "DATA_PATH_OR_URL = \"https://docs.google.com/spreadsheets/d/1B9RTjgPSEWyQzDr-CQJmCYRriaBIaGq2WEkfp2TLTIA/edit?usp=sharing\"\n",
    "\n",
    "df = read_data_flex(DATA_PATH_OR_URL)\n",
    "quick_info(df, \"Raw Data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1cb31b",
   "metadata": {},
   "source": [
    "## 2) Basic EDA & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e87ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Histograms for numeric columns\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if num_cols:\n",
    "    df[num_cols].hist(bins=30, figsize=(14, 10))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "if len(num_cols) > 1:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(df[num_cols].corr(), annot=False)\n",
    "    plt.title(\"Correlation Heatmap (Numeric Features)\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c2e44b",
   "metadata": {},
   "source": [
    "## 3) Train/Test Split & Preprocessing\n",
    "\n",
    "- Target column expected: **`median_house_value`** (change if your file uses a different name)\n",
    "- Simple imputation for missing values\n",
    "- One-hot encoding for categoricals\n",
    "- Standard scaling for numerics (for some models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0febba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TARGET = \"median_house_value\"  # <-- change if needed\n",
    "\n",
    "assert TARGET in df.columns, f\"Target column '{TARGET}' not found in data. Please update TARGET.\"\n",
    "\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "\n",
    "num_cols, cat_cols = numeric_categorical_columns(X)\n",
    "\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_pipe, num_cols),\n",
    "    (\"cat\", categorical_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17cdac",
   "metadata": {},
   "source": [
    "## 4) Simple Linear Regression (Single Feature)\n",
    "\n",
    "We'll use `median_income` as a common strong predictor. If your dataset has a different income-related column, update below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d71ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "single_feature = \"median_income\"  # change if needed\n",
    "assert single_feature in X.columns, f\"'{single_feature}' not in columns. Please set to a valid numeric column.\"\n",
    "\n",
    "X_train_sf = X_train[[single_feature]]\n",
    "X_test_sf = X_test[[single_feature]]\n",
    "\n",
    "slr = LinearRegression()\n",
    "slr.fit(X_train_sf, y_train)\n",
    "pred_sf = slr.predict(X_test_sf)\n",
    "\n",
    "mse_sf = mean_squared_error(y_test, pred_sf)\n",
    "rmse_sf = np.sqrt(mse_sf)\n",
    "r2_sf = r2_score(y_test, pred_sf)\n",
    "\n",
    "print(\"Simple Linear Regression (feature = {}):\".format(single_feature))\n",
    "print(f\"MSE: {mse_sf:.2f}, RMSE: {rmse_sf:.2f}, R^2: {r2_sf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f75e90a",
   "metadata": {},
   "source": [
    "## 5) Multiple Linear Regression & Regularized Models\n",
    "\n",
    "We compare **Linear Regression**, **Ridge**, and **Lasso** using a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48644481",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(max_iter=10000)\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"Ridge\": {\"model__alpha\": [0.1, 1.0, 10.0]},\n",
    "    \"Lasso\": {\"model__alpha\": [0.001, 0.01, 0.1, 1.0]}\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_pipelines = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[(\"preprocess\", preprocess),\n",
    "                          (\"model\", model)])\n",
    "    if name in param_grid:\n",
    "        grid = GridSearchCV(pipe, param_grid=param_grid[name], cv=5, scoring=\"r2\", n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_pipe = grid.best_estimator_\n",
    "        best_pipelines[name] = best_pipe\n",
    "        y_pred = best_pipe.predict(X_test)\n",
    "        used_model = best_pipe.named_steps[\"model\"]\n",
    "        best_params = grid.best_params_\n",
    "    else:\n",
    "        pipe.fit(X_train, y_train)\n",
    "        best_pipelines[name] = pipe\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        used_model = model\n",
    "        best_params = {}\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results.append((name, mse, rmse, r2, best_params))\n",
    "\n",
    "res_df = pd.DataFrame(results, columns=[\"Model\", \"MSE\", \"RMSE\", \"R2\", \"BestParams\"])\n",
    "display(res_df.sort_values(\"R2\", ascending=False))\n",
    "\n",
    "# Save the best model by R2\n",
    "best_name = res_df.sort_values(\"R2\", ascending=False).iloc[0][\"Model\"]\n",
    "joblib.dump(best_pipelines[best_name], \"partA_best_model.joblib\")\n",
    "print(f\"Saved best Part A model as 'partA_best_model.joblib' ({best_name}).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d467fbf",
   "metadata": {},
   "source": [
    "## 6) Conclusions\n",
    "\n",
    "- Compare metrics and choose the model with highest R² and reasonable RMSE.\n",
    "- Interpretability tip: Linear/Ridge/Lasso offer coefficients you can inspect."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
